# Profitable-Sports-Betting-Model-Results
This repo shows the results/profitability of a sports betting model I made in R and Python. In this repo I show the end results of using a machine learning algorithm (namely a random forest) to generate game win probabilities and exploit those probabilities to place long-term profitable moneyline wagers (known as positive EV betting). In this repo I show validity and trustworthiness of the algorithm through A) analysis of the random forest outputs as well as B) repeated backtesting on real sportsbooks odds to conirm that the model is indeed profitable. Please note that this repo shows THE RESULTS of the model NOT THE FEATURE ENGINEERING PROCESS. All of the analysis and backtesting was performed on a randomly selected 20% subset (test data) of the entire dataset with the remaining 80% (training data) being used to train the model. All feature engineering processes generated lagged variables for inputs to prevent data leakage (meaning all inputs used in the model will be available when it is time to make real predictions.  

## Explanation of Files:

### Model_training.py
This is a python code chunk showing the the spliting of the dataset into train and test sets. 20%  of the data was used for a test set where all validation/backtesting was done while the remaining 80% was used to train the random forest. Hyperparameters of the random forest are not disclosed. 

### Model_output_Regression_Curve.png
The random forest model produces probabilities that provide us a measure of the model's confidence/certainty in its predictions. If the probability is greater than .5 it predicts the team will win while if the probability is less than .5 it predicts the team will lose. Probabilities closer to 1 or 0 reflect a higher level of confidence in a team winning or losing respectively. In order to confirm that the model's outputed probabilities truly reflect the emperical frequency of teams winning or losing I conducted a logistic regression of the model's predictions for the test set against the true outcome for every game in the test dataset. After running a logistic regression I plotted the model's probabilities on the x-axis and partition the teams that won from those that lost on the y-axis (ie y~1 means the team won that game, while y~0 implies the team lost). We see that the model's predicted probabilities (black line) straddle the line y=x (blue line). This confirms that the model is indeed well-calibrated and produces probabilities that truly reflect a teams liklihood of winning a game. We also notice that the model is very conservative in its predictions as the model rarely produces a probability greater than .82 or less than .09. I confirm during backtesting against real data that this is non-problematic to generating profitable picks. 

### Model_Prediction_logistic_Regression.png
This is the output from running a logistic regression of the model's predicted probabilistic outputs against the true binary outcomes of the test data set. We first see that the model obtains a 63% raw accuracy which is statistically significant since our test set is indeed balanced at approx 50% win/lose teams. I focus on the p-value of the coefficient for the model's predictions which is .000 (approx 0) allowig me to reject the hypothesis that my model has no predictive power and accept the alternative (ie I can trust that the model has predictive power).  
